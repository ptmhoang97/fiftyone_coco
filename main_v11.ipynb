{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Download_COCO_dataset_from_FiftyOne.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptmhoang97/get_dataset_from_fiftyone_coco/blob/main/main_v11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeYW4UR-HR8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf49d0c-8e0d-4631-d4dc-b492e4061169"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjLb5bQpM_5U"
      },
      "source": [
        "# COCO_DATASET_YEAR can be '2014' or '2017'\n",
        "COCO_DATASET_YEAR = '2017'\n",
        "# COCO_DATASET_TYPE can be 'train' or 'validation'\n",
        "COCO_DATASET_TYPE = 'train'\n",
        "# Check below\n",
        "COCO_DATASET_CLASS = 'car'\n",
        "# scale of train dataset, \"test dataset = 1 - train dataset\"\n",
        "scale_train = 0.8"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXZ4dniCakXu"
      },
      "source": [
        "#* COCO_DATASET_CLASS\n",
        "person,\n",
        "bicycle,\n",
        "car,\n",
        "motorcycle,\n",
        "airplane,\n",
        "bus,\n",
        "train,\n",
        "truck,\n",
        "boat,\n",
        "traffic light,\n",
        "fire hydrant,\n",
        "stop sign,\n",
        "parking meter,\n",
        "bench,\n",
        "bird,\n",
        "cat,\n",
        "dog,\n",
        "horse,\n",
        "sheep,\n",
        "cow,\n",
        "elephant,\n",
        "bear,\n",
        "zebra,\n",
        "giraffe,\n",
        "backpack,\n",
        "umbrella,\n",
        "handbag,\n",
        "tie,\n",
        "suitcase,\n",
        "frisbee,\n",
        "skis,\n",
        "snowboard,\n",
        "sports ball,\n",
        "kite,\n",
        "baseball bat,\n",
        "baseball glove,\n",
        "skateboard,\n",
        "surfboard,\n",
        "tennis racket,\n",
        "bottle,\n",
        "wine glass,\n",
        "cup,\n",
        "fork,\n",
        "knife,\n",
        "spoon,\n",
        "bowl,\n",
        "banana,\n",
        "apple,\n",
        "sandwich,\n",
        "orange,\n",
        "broccoli,\n",
        "carrot,\n",
        "hot dog,\n",
        "pizza,\n",
        "donut,\n",
        "cake,\n",
        "chair,\n",
        "couch,\n",
        "potted plant,\n",
        "bed,\n",
        "dining table,\n",
        "toilet,\n",
        "tv,\n",
        "laptop,\n",
        "mouse,\n",
        "remote,\n",
        "keyboard,\n",
        "cell phone,\n",
        "microwave,\n",
        "oven,\n",
        "toaster,\n",
        "sink,\n",
        "refrigerator,\n",
        "book,\n",
        "clock,\n",
        "vase,\n",
        "scissors,\n",
        "teddy bear,\n",
        "hair drier,\n",
        "toothbrush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVCoPzo-Y_hx"
      },
      "source": [
        "#1. Install FiftyOne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5olqJLBwBDd"
      },
      "source": [
        "!pip install fiftyone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UncBiqxQF9NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2d72e6-a2c4-4b27-ccbd-dc41056222dd"
      },
      "source": [
        "!fiftyone --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FiftyOne v0.14.3, Voxel51, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"opencv-python-headless<4.3\""
      ],
      "metadata": {
        "id": "4xc6D31j50YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23329bb-9627-454b-87c3-80f065951e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless<4.3 in /usr/local/lib/python3.7/dist-packages (4.2.0.34)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless<4.3) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhqXQy9TNXxD"
      },
      "source": [
        "import fiftyone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiQOevbWZO7Z"
      },
      "source": [
        "#2. Download images and generate annotation files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSe44Q9TwDHG"
      },
      "source": [
        "import fiftyone.zoo as foz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FElPq3RMwYON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc759fe-35c5-4d93-cbf2-cadbbb6d5487"
      },
      "source": [
        "import os\n",
        "\n",
        "print(os.name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jDPHMjJVomC",
        "outputId": "c69cefec-2fe2-468e-879b-0174a2fbe92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_name_raw = 'coco{}_{}_{}'.format(COCO_DATASET_YEAR,COCO_DATASET_TYPE,COCO_DATASET_CLASS)\n",
        "print(dataset_name_raw)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco2017_train_car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BTlQuBxNCuL"
      },
      "source": [
        "paths = {\n",
        "    'COCO_DATASET_PATH': os.path.join('fiftyone', 'coco-{}'.format(COCO_DATASET_YEAR)),\n",
        "    'RESULT_PATH': os.path.join('fiftyone', 'coco-{}'.format(COCO_DATASET_YEAR), dataset_name_raw),\n",
        " }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ74FEAUyJH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d33ec2-ef08-44b6-b573-5203ba05b7aa"
      },
      "source": [
        "dataset = foz.load_zoo_dataset(name = 'coco-{}'.format(COCO_DATASET_YEAR),\\\n",
        "                               classes = COCO_DATASET_CLASS,\\\n",
        "                               split = COCO_DATASET_TYPE,\\\n",
        "                               dataset_dir = paths['COCO_DATASET_PATH'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to 'fiftyone/coco-2017/train' if necessary\n",
            "Found annotations at 'fiftyone/coco-2017/raw/instances_train2017.json'\n",
            "3664 images found; downloading the remaining 8587\n",
            " 100% |████████████████| 8587/8587 [13.3m elapsed, 0s remaining, 11.0 images/s]      \n",
            "Writing annotations for 14714 downloaded samples to 'fiftyone/coco-2017/train/labels.json'\n",
            "Dataset info written to 'fiftyone/coco-2017/info.json'\n",
            "Loading existing dataset 'coco-2017-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm4dp5vjAI_u",
        "outputId": "74a4e65e-b93f-49ed-ab5c-f83c83868797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir {paths['RESULT_PATH']}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘fiftyone/coco-2017/coco2017_train_car’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoxwEH-Mm08g"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "# import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNLKl1d5lTUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f95652c-1941-4bca-f47f-87a67994f2d7"
      },
      "source": [
        "resultDir=paths['RESULT_PATH']\n",
        "srcImageDir = paths['COCO_DATASET_PATH'] + '/{}/{}'.format(COCO_DATASET_TYPE,'data')\n",
        "srcAnnoDir = paths['COCO_DATASET_PATH'] + '/{}'.format('raw')\n",
        "datasets_list=[]\n",
        "if COCO_DATASET_TYPE == 'validation':\n",
        "    temp = 'val' + COCO_DATASET_YEAR\n",
        "    datasets_list = [temp]\n",
        "elif COCO_DATASET_TYPE == 'train':\n",
        "    temp = 'train' + COCO_DATASET_YEAR\n",
        "    datasets_list = [temp]\n",
        "classes_names = [COCO_DATASET_CLASS]\n",
        "print(datasets_list)\n",
        "print(classes_names)\n",
        "print(\"resultDir: \" + str(resultDir))\n",
        "print(\"srcImageDir: \" + str(srcImageDir))\n",
        "print(\"srcAnnoDir: \" + str(srcAnnoDir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train2017']\n",
            "['car']\n",
            "resultDir: fiftyone/coco-2017/coco2017_train_car\n",
            "srcImageDir: fiftyone/coco-2017/train/data\n",
            "srcAnnoDir: fiftyone/coco-2017/raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA28w0-AmrGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2895ef12-66d6-47ad-8603-0b2ca974ef8e"
      },
      "source": [
        "headstr = \"\"\"\\\n",
        "<annotation>\n",
        "    <folder>VOC</folder>\n",
        "    <filename>%s</filename>\n",
        "    <source>\n",
        "        <database>My Database</database>\n",
        "        <annotation>COCO</annotation>\n",
        "        <image>flickr</image>\n",
        "        <flickrid>NULL</flickrid>\n",
        "    </source>\n",
        "    <owner>\n",
        "        <flickrid>NULL</flickrid>\n",
        "        <name>company</name>\n",
        "    </owner>\n",
        "    <size>\n",
        "        <width>%d</width>\n",
        "        <height>%d</height>\n",
        "        <depth>%d</depth>\n",
        "    </size>\n",
        "    <segmented>0</segmented>\n",
        "\"\"\"\n",
        "objstr = \"\"\"\\\n",
        "    <object>\n",
        "        <name>%s</name>\n",
        "        <pose>Unspecified</pose>\n",
        "        <truncated>0</truncated>\n",
        "        <difficult>0</difficult>\n",
        "        <bndbox>\n",
        "            <xmin>%d</xmin>\n",
        "            <ymin>%d</ymin>\n",
        "            <xmax>%d</xmax>\n",
        "            <ymax>%d</ymax>\n",
        "        </bndbox>\n",
        "    </object>\n",
        "\"\"\"\n",
        " \n",
        "tailstr = '''\\\n",
        "</annotation>\n",
        "'''\n",
        " \n",
        "#if the dir is not exists,make it,else delete it\n",
        "def id2name(coco):\n",
        "    classes=dict()\n",
        "    for cls in coco.dataset['categories']:\n",
        "        classes[cls['id']]=cls['name']\n",
        "    return classes\n",
        " \n",
        "def write_xml(anno_path,head, objs, tail):\n",
        "    f = open(anno_path, \"w\")\n",
        "    f.write(head)\n",
        "    for obj in objs:\n",
        "        f.write(objstr%(obj[0],obj[1],obj[2],obj[3],obj[4]))\n",
        "    f.write(tail)\n",
        " \n",
        "def save_annotations_and_imgs(coco,dataset,filename,objs):\n",
        "    #eg:COCO_train2014_000000196610.jpg-->COCO_train2014_000000196610.xml\n",
        "    result_anno_path = '{}/{}{}'.format(resultDir,filename[:-3],'xml')\n",
        "    #print(result_anno_path)\n",
        "    src_img_path = '{}/{}'.format(srcImageDir,filename)\n",
        "    #print(anno_path)\n",
        "    #print(src_img_path)\n",
        "    dst_imgpath = '{}/{}'.format(resultDir,filename)\n",
        "    #print(dst_imgpath)\n",
        "    img=cv2.imread(src_img_path)\n",
        "    #if (img.shape[2] == 1):\n",
        "    #    print(filename + \" not a RGB image\")\n",
        "     #   return\n",
        "    shutil.copy(src_img_path, dst_imgpath)\n",
        " \n",
        "    head=headstr % (filename, img.shape[1], img.shape[0], img.shape[2])\n",
        "    tail = tailstr\n",
        "    write_xml(result_anno_path,head, objs, tail)\n",
        " \n",
        " \n",
        "def showimg(coco,dataset,img,classes,cls_id,show=True):\n",
        "    #global dataDir\n",
        "    path = '{}/{}'.format(srcImageDir,img['file_name'])\n",
        "    #print(path)\n",
        "    I=Image.open(path)\n",
        "    #By id, get comment information\n",
        "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=cls_id, iscrowd=None)\n",
        "    # print(annIds)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    # print(anns)\n",
        "    # coco.showAnns(anns)\n",
        "    objs = []\n",
        "    for ann in anns:\n",
        "        class_name=classes[ann['category_id']]\n",
        "        if class_name in classes_names:\n",
        "            #print(class_name)\n",
        "            if 'bbox' in ann:\n",
        "                bbox=ann['bbox']\n",
        "                xmin = int(bbox[0])\n",
        "                ymin = int(bbox[1])\n",
        "                xmax = int(bbox[2] + bbox[0])\n",
        "                ymax = int(bbox[3] + bbox[1])\n",
        "                obj = [class_name, xmin, ymin, xmax, ymax]\n",
        "                objs.append(obj)\n",
        "                draw = ImageDraw.Draw(I)\n",
        "                draw.rectangle([xmin, ymin, xmax, ymax])\n",
        "    if show:\n",
        "        plt.figure()\n",
        "        plt.axis('off')\n",
        "        plt.imshow(I)\n",
        "        plt.show()\n",
        " \n",
        "    return objs\n",
        "\n",
        "for dataset in datasets_list:\n",
        "    #./COCO/annotations/instances_train2014.json\n",
        "    annFile='{}/instances_{}.json'.format(srcAnnoDir,dataset)\n",
        "    #print(annFile)\n",
        "    #COCO API for initializing annotated data\n",
        "    coco = COCO(annFile)\n",
        " \n",
        "    #show all classes in coco\n",
        "    classes = id2name(coco)\n",
        "    #print(classes)\n",
        "    #[1, 2, 3, 4, 6, 8]\n",
        "    classes_ids = coco.getCatIds(catNms=classes_names)\n",
        "    #print(classes_ids)\n",
        "    for cls in classes_names:\n",
        "        #Get ID number of this class\n",
        "        cls_id=coco.getCatIds(catNms=[cls])\n",
        "        img_ids=coco.getImgIds(catIds=cls_id)\n",
        "        #print(cls,len(img_ids))\n",
        "        # imgIds=img_ids[0:10]\n",
        "        for imgId in tqdm(img_ids):\n",
        "            img = coco.loadImgs(imgId)[0]\n",
        "            filename = img['file_name']\n",
        "            # print(filename)\n",
        "            objs=showimg(coco, dataset, img, classes,classes_ids,show=False)\n",
        "            #print(objs)\n",
        "            save_annotations_and_imgs(coco, dataset, filename, objs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=18.33s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12251/12251 [03:17<00:00, 61.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-i3PCKZlyv"
      },
      "source": [
        "#3. Split VOC dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name_VOC = \"{0}_VOC\".format(dataset_name_raw)\n",
        "dataset_name_VOC_zip = \"{0}.zip\".format(dataset_name_VOC)"
      ],
      "metadata": {
        "id": "uzZZX7CGGFne"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_raw_location = paths['RESULT_PATH']"
      ],
      "metadata": {
        "id": "pRT5Up55BpHl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_VOC_location = \"/content/{0}\".format(dataset_name_VOC)\n",
        "file_VOC_location_zip = \"/content/{0}.zip\".format(dataset_name_VOC)"
      ],
      "metadata": {
        "id": "slWUswJtHxG-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copytree(file_raw_location, file_VOC_location)"
      ],
      "metadata": {
        "id": "nVgcikXpFPR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b8c07cf-c539-4643-e669-6017ece38b95"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/coco2017_train_car_VOC'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Pv0W7w04BbAp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def convert_png_to_jpg(file_location):\n",
        "    pattern = '*.png'\n",
        "    image_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            image_path.append(full_path)\n",
        "    \n",
        "    if not image_path:\n",
        "        print(\"No png images\")\n",
        "    else:\n",
        "        print(\"Converting png to jpg ...\")\n",
        "        for path in image_path:\n",
        "            path_png = '{}'.format(path)\n",
        "            path_jpg = path_png.replace(\".png\",\".jpg\")\n",
        "            \n",
        "            # Convert the link with '\\' to '\\\\' so that it can pass to Image.open() \n",
        "            path_png = path_png.encode('unicode-escape').decode()\n",
        "            path_jpg = path_jpg.encode('unicode-escape').decode()\n",
        "\n",
        "            img_png = Image.open(path_png)\n",
        "            img_png_rbg = img_png.convert('RGB')\n",
        "            img_png_rbg.save(path_jpg)\n",
        "        print(\"Done converting!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def delete_all_file(file_location,type_file):\n",
        "    pattern = '*.{0}'.format(type_file)\n",
        "    file_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            file_path.append(full_path)\n",
        "\n",
        "    if not file_path:\n",
        "        print(\"No files with type: \" + str(type_file))\n",
        "    else:\n",
        "        print(\"Deleting all files with type: \" + str(type_file))\n",
        "        for path in file_path:\n",
        "            if path.endswith(type_file):\n",
        "                os.remove(path)\n",
        "        print(\"Done deleting!\")"
      ],
      "metadata": {
        "id": "dsjpL80QDPJ9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import shutil\n",
        "\n",
        "def returnNotMatches(a, b):\n",
        "    return [[x for x in a if x not in b], [x for x in b if x not in a]]\n",
        "\n",
        "def filter_files(file_location,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    paths = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        path = path[:-4]\n",
        "        paths.append(path)\n",
        "    return paths\n",
        "\n",
        "def check_pair_dataset(file_location,type_file_pic,type_file_anno):\n",
        "    path_jpg = filter_files(file_location,type_file_pic)\n",
        "    path_txt = filter_files(file_location,type_file_anno)\n",
        "\n",
        "    for path in path_txt:\n",
        "        if path == \"classes\":\n",
        "            path_txt.remove(\"classes\")\n",
        "    print(\"Checking pair dataset ...\")\n",
        "    if returnNotMatches(path_jpg,path_txt)[0]:\n",
        "        raise Exception(\"Files \" + type_file_pic + \": \" + str(returnNotMatches(path_jpg,path_txt)[0]) + \" miss \" + type_file_anno + \" files\")\n",
        "    elif returnNotMatches(path_jpg,path_txt)[1]:\n",
        "        raise Exception(\"Files \" + type_file_anno + \": \" + str(returnNotMatches(path_jpg,path_txt)[1]) + \" miss \" + type_file_pic + \" files\")\n",
        "    else:\n",
        "        pass\n",
        "    print(\"Done checking! No mismtach!\")"
      ],
      "metadata": {
        "id": "Elyt0hSSEtU2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    with open(file_name, 'w') as f:\n",
        "        f.writelines(lines)\n",
        "        f.close()\n",
        "\n",
        "def rename_file_with_order(file_location,name_file,start_count_number,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    file_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            file_path.append(full_path)\n",
        "\n",
        "    # Sort to file_path with order from small to big\n",
        "    print(str(type_file) + \" - before sort: \" + str(file_path))\n",
        "    file_path.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    print(\"after sort: \" + str(file_path))\n",
        "    temp_count = start_count_number\n",
        "\n",
        "\n",
        "    for path in file_path:\n",
        "        name = \"{0}_{1}\".format(name_file,temp_count)\n",
        "        start = path.rfind(\"/\")\n",
        "        end = path.rfind(\".\")\n",
        "\n",
        "        start_part = path[:start+1]\n",
        "        end_part = path[end:]\n",
        "        \n",
        "        old_name = path\n",
        "        new_name = start_part + name + end_part\n",
        "\n",
        "        if type_file == \"xml\":\n",
        "            replace_text = \"    <filename>{0}.jpg</filename>\\n\".format(name)\n",
        "            replace_line(old_name,2,replace_text)\n",
        "        \n",
        "        os.rename(old_name,new_name)\n",
        "        temp_count+=1\n",
        "\n",
        "def rename_picFile_and_annoFile_with_order(file_location,name_file,start_count_number,type_pic_file,type_anno_file):\n",
        "    print(\"Renaming files ...\")\n",
        "\n",
        "    # Rename pic file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_pic_file)  \n",
        "    # Rename anno file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_anno_file)"
      ],
      "metadata": {
        "id": "w6jEF8X0HRHX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import shutil\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "import math\n",
        "\n",
        "def round_up_to_even(f):\n",
        "    return math.ceil(f / 2.) * 2\n",
        "\n",
        "def split_dataset(file_location,scale_train):\n",
        "    print(\"Splitting dataset ...\")\n",
        "\n",
        "    paths = {\n",
        "        'TRAIN_PATH': os.path.join(file_location,\"train\"),\n",
        "        'TEST_PATH': os.path.join(file_location,\"test\"),\n",
        "    }\n",
        "            \n",
        "    files = os.listdir(file_location)\n",
        "    dataset_files = []\n",
        "    for file_name in files:\n",
        "        if file_name.endswith(\"jpg\") or file_name.endswith(\"xml\"):\n",
        "            dataset_files.append(file_name)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    for path in paths.values():\n",
        "        if not os.path.exists(path):\n",
        "            !mkdir {path}\n",
        "        else:\n",
        "            !rm -rf {path}\n",
        "            !mkdir {path}\n",
        "\n",
        "    total_dataset = len(dataset_files) \n",
        "    num_train_dataset = round_up_to_even(total_dataset*scale_train)\n",
        "\n",
        "    print(\"total_dataset: \" + str(total_dataset))\n",
        "    print(\"scale_train: \" + str(scale_train))\n",
        "    print(\"num_train_dataset: \" + str(num_train_dataset))\n",
        "    print(\"num_test_dataset: \" + str(total_dataset - num_train_dataset))\n",
        "\n",
        "    # Sort to split files with order from small to big\n",
        "    print(\"before sort: \" + str(dataset_files))\n",
        "    dataset_files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    print(\"after sort: \" + str(dataset_files))\n",
        "\n",
        "    # Cut file to train and test folder\n",
        "    for idx,files in enumerate(dataset_files):\n",
        "        # print(files)\n",
        "        if idx < num_train_dataset:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TRAIN_PATH'])\n",
        "        else:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TEST_PATH'])\n",
        "\n",
        "    # Re-count number of files in train and test folder after cut\n",
        "    train_files = os.listdir(paths['TRAIN_PATH'])\n",
        "    test_files = os.listdir(paths['TEST_PATH'])\n",
        "\n",
        "    print(\"files in train folder after cut: \" + str(len(train_files)))\n",
        "    print(\"files in test folder after cut: \" + str(len(test_files)))"
      ],
      "metadata": {
        "cellView": "code",
        "id": "_McVyqM2Njb4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_png_to_jpg(file_VOC_location)"
      ],
      "metadata": {
        "id": "EEzeVuPgByxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701e1cff-d0fd-4341-b020-1b444f3e6e2a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No png images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delete_all_file(file_VOC_location,\"png\")"
      ],
      "metadata": {
        "id": "jU9aGsyRw5_N",
        "outputId": "f0caac9b-de01-4185-9011-477b26e113d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No files with type: png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_pair_dataset(file_VOC_location,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "id": "VVLQIoT7EDdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981ee5c1-d8e5-484d-f460-2332fe4775c6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking pair dataset ...\n",
            "Done checking! No mismtach!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = COCO_DATASET_CLASS + \"_COCO\""
      ],
      "metadata": {
        "id": "9LqRlFGzDlef"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename_picFile_and_annoFile_with_order(file_VOC_location,file_name, 1 ,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "id": "eL3hsm5wE3pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(file_VOC_location,scale_train)"
      ],
      "metadata": {
        "id": "M2bnwYmJH1v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd626db-6e9d-47e8-fde8-074405bcaff3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting dataset ...\n",
            "total_dataset: 44\n",
            "scale_train: 0.8\n",
            "num_train_dataset: 36\n",
            "num_test_dataset: 8\n",
            "before sort: ['car_COCO_5.jpg', 'car_COCO_7.xml', 'car_COCO_14.jpg', 'car_COCO_9.jpg', 'car_COCO_12.jpg', 'car_COCO_13.jpg', 'car_COCO_12.xml', 'car_COCO_10.jpg', 'car_COCO_21.xml', 'car_COCO_19.jpg', 'car_COCO_20.xml', 'car_COCO_15.xml', 'car_COCO_1.xml', 'car_COCO_10.xml', 'car_COCO_21.jpg', 'car_COCO_18.jpg', 'car_COCO_16.jpg', 'car_COCO_6.jpg', 'car_COCO_19.xml', 'car_COCO_17.jpg', 'car_COCO_8.jpg', 'car_COCO_6.xml', 'car_COCO_18.xml', 'car_COCO_4.xml', 'car_COCO_2.xml', 'car_COCO_13.xml', 'car_COCO_14.xml', 'car_COCO_22.jpg', 'car_COCO_15.jpg', 'car_COCO_11.jpg', 'car_COCO_3.xml', 'car_COCO_20.jpg', 'car_COCO_17.xml', 'car_COCO_3.jpg', 'car_COCO_1.jpg', 'car_COCO_7.jpg', 'car_COCO_22.xml', 'car_COCO_11.xml', 'car_COCO_4.jpg', 'car_COCO_9.xml', 'car_COCO_2.jpg', 'car_COCO_5.xml', 'car_COCO_16.xml', 'car_COCO_8.xml']\n",
            "after sort: ['car_COCO_1.xml', 'car_COCO_1.jpg', 'car_COCO_2.xml', 'car_COCO_2.jpg', 'car_COCO_3.xml', 'car_COCO_3.jpg', 'car_COCO_4.xml', 'car_COCO_4.jpg', 'car_COCO_5.jpg', 'car_COCO_5.xml', 'car_COCO_6.jpg', 'car_COCO_6.xml', 'car_COCO_7.xml', 'car_COCO_7.jpg', 'car_COCO_8.jpg', 'car_COCO_8.xml', 'car_COCO_9.jpg', 'car_COCO_9.xml', 'car_COCO_10.jpg', 'car_COCO_10.xml', 'car_COCO_11.jpg', 'car_COCO_11.xml', 'car_COCO_12.jpg', 'car_COCO_12.xml', 'car_COCO_13.jpg', 'car_COCO_13.xml', 'car_COCO_14.jpg', 'car_COCO_14.xml', 'car_COCO_15.xml', 'car_COCO_15.jpg', 'car_COCO_16.jpg', 'car_COCO_16.xml', 'car_COCO_17.jpg', 'car_COCO_17.xml', 'car_COCO_18.jpg', 'car_COCO_18.xml', 'car_COCO_19.jpg', 'car_COCO_19.xml', 'car_COCO_20.xml', 'car_COCO_20.jpg', 'car_COCO_21.xml', 'car_COCO_21.jpg', 'car_COCO_22.jpg', 'car_COCO_22.xml']\n",
            "files in train folder after cut: 36\n",
            "files in test folder after cut: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf \"/content/coco2017_train_car_VOC\""
      ],
      "metadata": {
        "id": "iZLrNZE8V0Dk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Zip and copy dataset to GG drive"
      ],
      "metadata": {
        "id": "gnmFtQQ9s7xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r {dataset_name_VOC_zip} {dataset_name_VOC}"
      ],
      "metadata": {
        "id": "A4SNVRpkQ1Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {dataset_name_VOC_zip} \"/content/gdrive/MyDrive/_dataset\""
      ],
      "metadata": {
        "id": "6PIaD_z7LbiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B-1HiUfxt2E1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}