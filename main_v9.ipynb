{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Download_COCO_dataset_from_FiftyOne.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptmhoang97/get_dataset_from_fiftyone_coco/blob/main/main_v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeYW4UR-HR8n"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjLb5bQpM_5U"
      },
      "source": [
        "# COCO_DATASET_YEAR can be '2014' or '2017'\n",
        "COCO_DATASET_YEAR = '2017'\n",
        "# COCO_DATASET_TYPE can be 'train' or 'validation'\n",
        "COCO_DATASET_TYPE = 'train'\n",
        "# Check below\n",
        "COCO_DATASET_CLASS = 'car'\n",
        "# scale of train dataset, \"test dataset = 1 - train dataset\"\n",
        "scale_train = 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXZ4dniCakXu"
      },
      "source": [
        "#* COCO_DATASET_CLASS\n",
        "person,\n",
        "bicycle,\n",
        "car,\n",
        "motorcycle,\n",
        "airplane,\n",
        "bus,\n",
        "train,\n",
        "truck,\n",
        "boat,\n",
        "traffic light,\n",
        "fire hydrant,\n",
        "stop sign,\n",
        "parking meter,\n",
        "bench,\n",
        "bird,\n",
        "cat,\n",
        "dog,\n",
        "horse,\n",
        "sheep,\n",
        "cow,\n",
        "elephant,\n",
        "bear,\n",
        "zebra,\n",
        "giraffe,\n",
        "backpack,\n",
        "umbrella,\n",
        "handbag,\n",
        "tie,\n",
        "suitcase,\n",
        "frisbee,\n",
        "skis,\n",
        "snowboard,\n",
        "sports ball,\n",
        "kite,\n",
        "baseball bat,\n",
        "baseball glove,\n",
        "skateboard,\n",
        "surfboard,\n",
        "tennis racket,\n",
        "bottle,\n",
        "wine glass,\n",
        "cup,\n",
        "fork,\n",
        "knife,\n",
        "spoon,\n",
        "bowl,\n",
        "banana,\n",
        "apple,\n",
        "sandwich,\n",
        "orange,\n",
        "broccoli,\n",
        "carrot,\n",
        "hot dog,\n",
        "pizza,\n",
        "donut,\n",
        "cake,\n",
        "chair,\n",
        "couch,\n",
        "potted plant,\n",
        "bed,\n",
        "dining table,\n",
        "toilet,\n",
        "tv,\n",
        "laptop,\n",
        "mouse,\n",
        "remote,\n",
        "keyboard,\n",
        "cell phone,\n",
        "microwave,\n",
        "oven,\n",
        "toaster,\n",
        "sink,\n",
        "refrigerator,\n",
        "book,\n",
        "clock,\n",
        "vase,\n",
        "scissors,\n",
        "teddy bear,\n",
        "hair drier,\n",
        "toothbrush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVCoPzo-Y_hx"
      },
      "source": [
        "#1. Install FiftyOne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5olqJLBwBDd"
      },
      "source": [
        "!pip install fiftyone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UncBiqxQF9NS"
      },
      "source": [
        "!fiftyone --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"opencv-python-headless<4.3\""
      ],
      "metadata": {
        "id": "4xc6D31j50YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhqXQy9TNXxD"
      },
      "source": [
        "import fiftyone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiQOevbWZO7Z"
      },
      "source": [
        "#2. Download images and generate annotation files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSe44Q9TwDHG"
      },
      "source": [
        "import fiftyone.zoo as foz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FElPq3RMwYON"
      },
      "source": [
        "import os\n",
        "print(os.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jDPHMjJVomC"
      },
      "source": [
        "dataset_name_raw = 'coco{}_{}_{}'.format(COCO_DATASET_YEAR,COCO_DATASET_TYPE,COCO_DATASET_CLASS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BTlQuBxNCuL"
      },
      "source": [
        "paths = {\n",
        "    'COCO_DATASET_PATH': os.path.join('fiftyone', 'coco-{}'.format(COCO_DATASET_YEAR)),\n",
        "    'RESULT_PATH': os.path.join('fiftyone', 'coco-{}'.format(COCO_DATASET_YEAR), dataset_name_raw),\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ74FEAUyJH2"
      },
      "source": [
        "dataset = foz.load_zoo_dataset(name = 'coco-{}'.format(COCO_DATASET_YEAR),\\\n",
        "                               classes = COCO_DATASET_CLASS,\\\n",
        "                               split = COCO_DATASET_TYPE,\\\n",
        "                               dataset_dir = paths['COCO_DATASET_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm4dp5vjAI_u"
      },
      "source": [
        "!mkdir {paths['RESULT_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoxwEH-Mm08g"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "# import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNLKl1d5lTUA"
      },
      "source": [
        "resultDir=paths['RESULT_PATH']\n",
        "srcImageDir = paths['COCO_DATASET_PATH'] + '/{}/{}'.format(COCO_DATASET_TYPE,'data')\n",
        "srcAnnoDir = paths['COCO_DATASET_PATH'] + '/{}'.format('raw')\n",
        "datasets_list=[]\n",
        "if COCO_DATASET_TYPE == 'validation':\n",
        "    temp = 'val' + COCO_DATASET_YEAR\n",
        "    datasets_list = [temp]\n",
        "elif COCO_DATASET_TYPE == 'train':\n",
        "    temp = 'train' + COCO_DATASET_YEAR\n",
        "    datasets_list = [temp]\n",
        "classes_names = [COCO_DATASET_CLASS]\n",
        "print(datasets_list)\n",
        "print(classes_names)\n",
        "print(\"resultDir: \" + str(resultDir))\n",
        "print(\"srcImageDir: \" + str(srcImageDir))\n",
        "print(\"srcAnnoDir: \" + str(srcAnnoDir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA28w0-AmrGB"
      },
      "source": [
        "headstr = \"\"\"\\\n",
        "<annotation>\n",
        "    <folder>VOC</folder>\n",
        "    <filename>%s</filename>\n",
        "    <source>\n",
        "        <database>My Database</database>\n",
        "        <annotation>COCO</annotation>\n",
        "        <image>flickr</image>\n",
        "        <flickrid>NULL</flickrid>\n",
        "    </source>\n",
        "    <owner>\n",
        "        <flickrid>NULL</flickrid>\n",
        "        <name>company</name>\n",
        "    </owner>\n",
        "    <size>\n",
        "        <width>%d</width>\n",
        "        <height>%d</height>\n",
        "        <depth>%d</depth>\n",
        "    </size>\n",
        "    <segmented>0</segmented>\n",
        "\"\"\"\n",
        "objstr = \"\"\"\\\n",
        "    <object>\n",
        "        <name>%s</name>\n",
        "        <pose>Unspecified</pose>\n",
        "        <truncated>0</truncated>\n",
        "        <difficult>0</difficult>\n",
        "        <bndbox>\n",
        "            <xmin>%d</xmin>\n",
        "            <ymin>%d</ymin>\n",
        "            <xmax>%d</xmax>\n",
        "            <ymax>%d</ymax>\n",
        "        </bndbox>\n",
        "    </object>\n",
        "\"\"\"\n",
        " \n",
        "tailstr = '''\\\n",
        "</annotation>\n",
        "'''\n",
        " \n",
        "#if the dir is not exists,make it,else delete it\n",
        "def id2name(coco):\n",
        "    classes=dict()\n",
        "    for cls in coco.dataset['categories']:\n",
        "        classes[cls['id']]=cls['name']\n",
        "    return classes\n",
        " \n",
        "def write_xml(anno_path,head, objs, tail):\n",
        "    f = open(anno_path, \"w\")\n",
        "    f.write(head)\n",
        "    for obj in objs:\n",
        "        f.write(objstr%(obj[0],obj[1],obj[2],obj[3],obj[4]))\n",
        "    f.write(tail)\n",
        " \n",
        "def save_annotations_and_imgs(coco,dataset,filename,objs):\n",
        "    #eg:COCO_train2014_000000196610.jpg-->COCO_train2014_000000196610.xml\n",
        "    result_anno_path = '{}/{}{}'.format(resultDir,filename[:-3],'xml')\n",
        "    #print(result_anno_path)\n",
        "    src_img_path = '{}/{}'.format(srcImageDir,filename)\n",
        "    #print(anno_path)\n",
        "    #print(src_img_path)\n",
        "    dst_imgpath = '{}/{}'.format(resultDir,filename)\n",
        "    #print(dst_imgpath)\n",
        "    img=cv2.imread(src_img_path)\n",
        "    #if (img.shape[2] == 1):\n",
        "    #    print(filename + \" not a RGB image\")\n",
        "     #   return\n",
        "    shutil.copy(src_img_path, dst_imgpath)\n",
        " \n",
        "    head=headstr % (filename, img.shape[1], img.shape[0], img.shape[2])\n",
        "    tail = tailstr\n",
        "    write_xml(result_anno_path,head, objs, tail)\n",
        " \n",
        " \n",
        "def showimg(coco,dataset,img,classes,cls_id,show=True):\n",
        "    #global dataDir\n",
        "    path = '{}/{}'.format(srcImageDir,img['file_name'])\n",
        "    #print(path)\n",
        "    I=Image.open(path)\n",
        "    #By id, get comment information\n",
        "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=cls_id, iscrowd=None)\n",
        "    # print(annIds)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    # print(anns)\n",
        "    # coco.showAnns(anns)\n",
        "    objs = []\n",
        "    for ann in anns:\n",
        "        class_name=classes[ann['category_id']]\n",
        "        if class_name in classes_names:\n",
        "            #print(class_name)\n",
        "            if 'bbox' in ann:\n",
        "                bbox=ann['bbox']\n",
        "                xmin = int(bbox[0])\n",
        "                ymin = int(bbox[1])\n",
        "                xmax = int(bbox[2] + bbox[0])\n",
        "                ymax = int(bbox[3] + bbox[1])\n",
        "                obj = [class_name, xmin, ymin, xmax, ymax]\n",
        "                objs.append(obj)\n",
        "                draw = ImageDraw.Draw(I)\n",
        "                draw.rectangle([xmin, ymin, xmax, ymax])\n",
        "    if show:\n",
        "        plt.figure()\n",
        "        plt.axis('off')\n",
        "        plt.imshow(I)\n",
        "        plt.show()\n",
        " \n",
        "    return objs\n",
        "\n",
        "for dataset in datasets_list:\n",
        "    #./COCO/annotations/instances_train2014.json\n",
        "    annFile='{}/instances_{}.json'.format(srcAnnoDir,dataset)\n",
        "    #print(annFile)\n",
        "    #COCO API for initializing annotated data\n",
        "    coco = COCO(annFile)\n",
        " \n",
        "    #show all classes in coco\n",
        "    classes = id2name(coco)\n",
        "    #print(classes)\n",
        "    #[1, 2, 3, 4, 6, 8]\n",
        "    classes_ids = coco.getCatIds(catNms=classes_names)\n",
        "    #print(classes_ids)\n",
        "    for cls in classes_names:\n",
        "        #Get ID number of this class\n",
        "        cls_id=coco.getCatIds(catNms=[cls])\n",
        "        img_ids=coco.getImgIds(catIds=cls_id)\n",
        "        #print(cls,len(img_ids))\n",
        "        # imgIds=img_ids[0:10]\n",
        "        for imgId in tqdm(img_ids):\n",
        "            img = coco.loadImgs(imgId)[0]\n",
        "            filename = img['file_name']\n",
        "            # print(filename)\n",
        "            objs=showimg(coco, dataset, img, classes,classes_ids,show=False)\n",
        "            #print(objs)\n",
        "            save_annotations_and_imgs(coco, dataset, filename, objs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-i3PCKZlyv"
      },
      "source": [
        "#3. Split VOC dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name_VOC = \"{0}_VOC\".format(dataset_name_raw)\n",
        "dataset_name_VOC_zip = \"{0}.zip\".format(dataset_name_VOC)"
      ],
      "metadata": {
        "id": "uzZZX7CGGFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_raw_location = paths['RESULT_PATH']"
      ],
      "metadata": {
        "id": "pRT5Up55BpHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_VOC_location = \"/content/{0}\".format(dataset_name_VOC)\n",
        "file_VOC_location_zip = \"/content/{0}.zip\".format(dataset_name_VOC)"
      ],
      "metadata": {
        "id": "slWUswJtHxG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copytree(file_raw_location, file_VOC_location)"
      ],
      "metadata": {
        "id": "nVgcikXpFPR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv0W7w04BbAp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def convert_png_to_jpg(file_location):\n",
        "    pattern = '*.png'\n",
        "    image_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            image_path.append(full_path)\n",
        "    \n",
        "    if not image_path:\n",
        "        print(\"No png images\")\n",
        "    else:\n",
        "        print(\"Converting png to jpg ...\")\n",
        "        for path in image_path:\n",
        "            path_png = '{}'.format(path)\n",
        "            path_jpg = path_png.replace(\".png\",\".jpg\")\n",
        "            \n",
        "            # Convert the link with '\\' to '\\\\' so that it can pass to Image.open() \n",
        "            path_png = path_png.encode('unicode-escape').decode()\n",
        "            path_jpg = path_jpg.encode('unicode-escape').decode()\n",
        "\n",
        "            img_png = Image.open(path_png)\n",
        "            img_png_rbg = img_png.convert('RGB')\n",
        "            img_png_rbg.save(path_jpg)\n",
        "        print(\"Done converting!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def delete_all_png(file_location):\n",
        "    pattern = '*.png'\n",
        "    image_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            image_path.append(full_path)\n",
        "\n",
        "    if not image_path:\n",
        "        print(\"No png images\")\n",
        "    else:\n",
        "        print(\"Deleting all png ...\")\n",
        "        for images in test:\n",
        "            if images.endswith(\".png\"):\n",
        "                os.remove(os.path.join(file_location, images))\n",
        "        print(\"Done deleting!\")"
      ],
      "metadata": {
        "id": "dsjpL80QDPJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import shutil\n",
        "\n",
        "def returnNotMatches(a, b):\n",
        "    return [[x for x in a if x not in b], [x for x in b if x not in a]]\n",
        "\n",
        "def filter_files(file_location,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    paths = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        path = path[:-4]\n",
        "        paths.append(path)\n",
        "    return paths\n",
        "\n",
        "def check_pair_dataset(file_location,type_file_pic,type_file_anno):\n",
        "    path_jpg = filter_files(file_location,type_file_pic)\n",
        "    path_txt = filter_files(file_location,type_file_anno)\n",
        "\n",
        "    for path in path_txt:\n",
        "        if path == \"classes\":\n",
        "            path_txt.remove(\"classes\")\n",
        "    print(\"Checking pair dataset ...\")\n",
        "    if returnNotMatches(path_jpg,path_txt)[0]:\n",
        "        raise Exception(\"Files \" + type_file_pic + \": \" + str(returnNotMatches(path_jpg,path_txt)[0]) + \" miss \" + type_file_anno + \" files\")\n",
        "    elif returnNotMatches(path_jpg,path_txt)[1]:\n",
        "        raise Exception(\"Files \" + type_file_anno + \": \" + str(returnNotMatches(path_jpg,path_txt)[1]) + \" miss \" + type_file_pic + \" files\")\n",
        "    else:\n",
        "        pass\n",
        "    print(\"Done checking! No mismtach!\")"
      ],
      "metadata": {
        "id": "Elyt0hSSEtU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    with open(file_name, 'w') as f:\n",
        "        f.writelines(lines)\n",
        "        f.close()\n",
        "\n",
        "def rename_file_with_order(file_location,name_file,start_count_number,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    file_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            file_path.append(full_path)\n",
        "\n",
        "    temp_count = start_count_number\n",
        "    \n",
        "    for path in file_path:\n",
        "        name = \"{0}_{1}\".format(name_file,temp_count)\n",
        "        start = path.rfind(\"/\")\n",
        "        end = path.rfind(\".\")\n",
        "\n",
        "        start_part = path[:start+1]\n",
        "        end_part = path[end:]\n",
        "        \n",
        "        old_name = path\n",
        "        new_name = start_part + name + end_part\n",
        "\n",
        "        if type_file == \"xml\":\n",
        "            replace_text = \"    <filename>{0}.jpg</filename>\\n\".format(name)\n",
        "            replace_line(old_name,2,replace_text)\n",
        "        \n",
        "        os.rename(old_name,new_name)\n",
        "        temp_count+=1\n",
        "\n",
        "def rename_picFile_and_annoFile_with_order(file_location,name_file,start_count_number,type_pic_file,type_anno_file):\n",
        "    print(\"Renaming files ...\")\n",
        "\n",
        "    # Rename pic file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_pic_file)  \n",
        "    # Rename anno file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_anno_file)"
      ],
      "metadata": {
        "id": "w6jEF8X0HRHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import shutil\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "import math\n",
        "\n",
        "def round_up_to_even(f):\n",
        "    return math.ceil(f / 2.) * 2\n",
        "\n",
        "def split_dataset(file_location,scale_train):\n",
        "    print(\"Splitting dataset ...\")\n",
        "\n",
        "    paths = {\n",
        "        'TRAIN_PATH': os.path.join(file_location,\"train\"),\n",
        "        'TEST_PATH': os.path.join(file_location,\"test\"),\n",
        "    }\n",
        "            \n",
        "    files = os.listdir(file_location)\n",
        "    dataset_files = []\n",
        "    for file_name in files:\n",
        "        if file_name.endswith(\"jpg\") or file_name.endswith(\"xml\"):\n",
        "            dataset_files.append(file_name)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    for path in paths.values():\n",
        "        if not os.path.exists(path):\n",
        "            !mkdir {path}\n",
        "        else:\n",
        "            !rm -rf {path}\n",
        "            !mkdir {path}\n",
        "\n",
        "    total_dataset = len(dataset_files) \n",
        "    num_train_dataset = round_up_to_even(total_dataset*scale_train)\n",
        "\n",
        "    print(\"total_dataset: \" + str(total_dataset))\n",
        "    print(\"scale_train: \" + str(scale_train))\n",
        "    print(\"num_train_dataset: \" + str(num_train_dataset))\n",
        "    print(\"num_test_dataset: \" + str(total_dataset - num_train_dataset))\n",
        "\n",
        "    # Sort to split files with order from small to big\n",
        "    print(\"before sort: \" + str(dataset_files))\n",
        "    dataset_files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    print(\"after sort: \" + str(dataset_files))\n",
        "\n",
        "    # Cut file to train and test folder\n",
        "    for idx,files in enumerate(dataset_files):\n",
        "        # print(files)\n",
        "        if idx < num_train_dataset:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TRAIN_PATH'])\n",
        "        else:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TEST_PATH'])\n",
        "\n",
        "    # Re-count number of files in train and test folder after cut\n",
        "    train_files = os.listdir(paths['TRAIN_PATH'])\n",
        "    test_files = os.listdir(paths['TEST_PATH'])\n",
        "\n",
        "    print(\"files in train folder after cut: \" + str(len(train_files)))\n",
        "    print(\"files in test folder after cut: \" + str(len(test_files)))"
      ],
      "metadata": {
        "cellView": "code",
        "id": "_McVyqM2Njb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_png_to_jpg(file_VOC_location)"
      ],
      "metadata": {
        "id": "EEzeVuPgByxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_all_png(file_VOC_location)"
      ],
      "metadata": {
        "id": "XeZyCJ7SB4Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_pair_dataset(file_VOC_location,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "id": "VVLQIoT7EDdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = COCO_DATASET_CLASS + \"_COCO\""
      ],
      "metadata": {
        "id": "9LqRlFGzDlef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename_picFile_and_annoFile_with_order(file_VOC_location,file_name, 1 ,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "id": "eL3hsm5wE3pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(file_VOC_location,scale_train)"
      ],
      "metadata": {
        "id": "M2bnwYmJH1v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/coco2017_train_car_VOC\""
      ],
      "metadata": {
        "id": "xusN504gEye_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Zip and copy dataset to GG drive"
      ],
      "metadata": {
        "id": "gnmFtQQ9s7xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r {dataset_name_VOC_zip} {dataset_name_VOC}"
      ],
      "metadata": {
        "id": "A4SNVRpkQ1Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {dataset_name_VOC_zip} \"/content/gdrive/MyDrive/_dataset\""
      ],
      "metadata": {
        "id": "6PIaD_z7LbiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B-1HiUfxt2E1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}